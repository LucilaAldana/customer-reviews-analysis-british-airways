{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c534552-70d0-4894-b76d-b4fe901fffb6",
   "metadata": {},
   "source": [
    "# **BRITISH AIRWAYS REVIEWS ANALYSIS**\n",
    "##### **by Lucila Aldana Quiñonez | Marketing Data Analyst**\n",
    "# **Keywords Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "619a20e1-28dc-46ed-9bd6-9fd7a4550a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb3bbb8-afaa-4831-9423-27877f85b837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324 entries, 0 to 1323\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   full_review      1324 non-null   object        \n",
      " 1   recommended      1324 non-null   object        \n",
      " 2   date             484 non-null    datetime64[ns]\n",
      " 3   sentiment_score  1324 non-null   float64       \n",
      " 4   sentiment        1324 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 51.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_review</th>\n",
       "      <th>recommended</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>service was mediocre at best.  Just returned f...</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA standards continue to decline.   BA standar...</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-02-10</td>\n",
       "      <td>-0.6428</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>won the race to the bottom\" .   Awful. Busines...</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-02-10</td>\n",
       "      <td>-0.4997</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not a reliable airline.   Not a reliable airli...</td>\n",
       "      <td>no</td>\n",
       "      <td>2023-02-10</td>\n",
       "      <td>-0.6281</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very disappointed.  The airplanes and the loun...</td>\n",
       "      <td>no</td>\n",
       "      <td>NaT</td>\n",
       "      <td>-0.9319</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         full_review recommended       date  \\\n",
       "0  service was mediocre at best.  Just returned f...          no 2023-03-10   \n",
       "1  BA standards continue to decline.   BA standar...          no 2023-02-10   \n",
       "2  won the race to the bottom\" .   Awful. Busines...          no 2023-02-10   \n",
       "3  Not a reliable airline.   Not a reliable airli...          no 2023-02-10   \n",
       "4  Very disappointed.  The airplanes and the loun...          no        NaT   \n",
       "\n",
       "   sentiment_score sentiment  \n",
       "0           0.8933  Positive  \n",
       "1          -0.6428  Negative  \n",
       "2          -0.4997  Negative  \n",
       "3          -0.6281  Negative  \n",
       "4          -0.9319  Negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the sentiment dataset\n",
    "sentiment_df = pd.read_csv(\n",
    "    r\"C:\\Users\\lucil\\Documents\\Education\\Data Analysis\\Tableau\\Projects Tableau\\British Airways Customer Reviews Analysis - by Lucila Aldana Quiñonez _ Marketing Data Analyst\\reviews_with_sentiment.csv\"\n",
    ")\n",
    "\n",
    "# Ensure date column is of datetime type\n",
    "sentiment_df['date'] = pd.to_datetime(\n",
    "    sentiment_df['date'],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Overview the data\n",
    "sentiment_df.info()\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7e4f81c-3794-415f-83ca-950b2663fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only non-recommending reviews\n",
    "df_no_rec = sentiment_df[sentiment_df[\"recommended\"] == \"no\"]\n",
    "\n",
    "neg_no = df_no_rec[df_no_rec[\"sentiment\"] == \"Negative\"]\n",
    "neu_no = df_no_rec[df_no_rec[\"sentiment\"] == \"Neutral\"]\n",
    "pos_no = df_no_rec[df_no_rec[\"sentiment\"] == \"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f894d6-76f7-43b2-9bc4-9a73f45db803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "C:\\Users\\lucil\\AppData\\Local\\Temp\\ipykernel_23664\\1958588847.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_no[\"clean_review\"] = neg_no[\"full_review\"].apply(clean_text)\n",
      "C:\\Users\\lucil\\AppData\\Local\\Temp\\ipykernel_23664\\1958588847.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neu_no[\"clean_review\"] = neu_no[\"full_review\"].apply(clean_text)\n",
      "C:\\Users\\lucil\\AppData\\Local\\Temp\\ipykernel_23664\\1958588847.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pos_no[\"clean_review\"] = pos_no[\"full_review\"].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "# Clean the text\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Add airline-specific stopwords\n",
    "airline_noise = {\n",
    "    \"ba\", \"british\", \"airways\", \"flight\", \"flights\",\n",
    "    \"airline\", \"plane\", \"airport\", \"london\", \"heathrow\"\n",
    "}\n",
    "\n",
    "stop_words = stop_words.union(airline_noise)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = [word for word in text.split() if word not in stop_words and len(word) > 2]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "neg_no[\"clean_review\"] = neg_no[\"full_review\"].apply(clean_text)\n",
    "neu_no[\"clean_review\"] = neu_no[\"full_review\"].apply(clean_text)\n",
    "pos_no[\"clean_review\"] = pos_no[\"full_review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f24a2cb-6ba9-4910-82a6-ad52c4a0cc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('service', 416),\n",
       "  ('class', 366),\n",
       "  ('seat', 359),\n",
       "  ('food', 316),\n",
       "  ('business', 311),\n",
       "  ('seats', 297),\n",
       "  ('cabin', 279),\n",
       "  ('crew', 274),\n",
       "  ('staff', 240),\n",
       "  ('one', 223),\n",
       "  ('time', 215),\n",
       "  ('would', 202),\n",
       "  ('economy', 200),\n",
       "  ('first', 200),\n",
       "  ('passengers', 184),\n",
       "  ('poor', 179),\n",
       "  ('hours', 173),\n",
       "  ('get', 162),\n",
       "  ('even', 157),\n",
       "  ('club', 143)],\n",
       " [('service', 20),\n",
       "  ('seats', 11),\n",
       "  ('served', 9),\n",
       "  ('crew', 9),\n",
       "  ('seat', 9),\n",
       "  ('cabin', 9),\n",
       "  ('food', 9),\n",
       "  ('business', 8),\n",
       "  ('class', 8),\n",
       "  ('meal', 8),\n",
       "  ('time', 8),\n",
       "  ('would', 8),\n",
       "  ('good', 8),\n",
       "  ('could', 7),\n",
       "  ('return', 7),\n",
       "  ('staff', 6),\n",
       "  ('get', 6),\n",
       "  ('one', 6),\n",
       "  ('drinks', 6),\n",
       "  ('flying', 6)],\n",
       " [('service', 270),\n",
       "  ('seat', 267),\n",
       "  ('class', 240),\n",
       "  ('crew', 226),\n",
       "  ('food', 225),\n",
       "  ('business', 204),\n",
       "  ('seats', 193),\n",
       "  ('time', 183),\n",
       "  ('cabin', 183),\n",
       "  ('one', 180),\n",
       "  ('economy', 165),\n",
       "  ('would', 153),\n",
       "  ('get', 152),\n",
       "  ('staff', 143),\n",
       "  ('good', 139),\n",
       "  ('first', 119),\n",
       "  ('meal', 113),\n",
       "  ('lounge', 107),\n",
       "  ('could', 107),\n",
       "  ('boarding', 107)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract top keywords per segment\n",
    "\n",
    "def top_keywords(series, n=20):\n",
    "    words = \" \".join(series).split()\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "top_neg = top_keywords(neg_no[\"clean_review\"])\n",
    "top_neu = top_keywords(neu_no[\"clean_review\"])\n",
    "top_pos = top_keywords(pos_no[\"clean_review\"])\n",
    "\n",
    "top_neg, top_neu, top_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b086a164-6446-4b4d-9c2a-bdea0bfcae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert keyword lists to DataFrames\n",
    "df_neg = pd.DataFrame(top_neg, columns=[\"keyword\", \"count\"])\n",
    "df_neg[\"sentiment\"] = \"Negative\"\n",
    "\n",
    "df_neu = pd.DataFrame(top_neu, columns=[\"keyword\", \"count\"])\n",
    "df_neu[\"sentiment\"] = \"Neutral\"\n",
    "\n",
    "df_pos = pd.DataFrame(top_pos, columns=[\"keyword\", \"count\"])\n",
    "df_pos[\"sentiment\"] = \"Positive\"\n",
    "\n",
    "# Combine all sentiments\n",
    "keywords_df = pd.concat([df_neg, df_neu, df_pos], ignore_index=True)\n",
    "\n",
    "# Segment label for future reuse\n",
    "keywords_df[\"segment\"] = \"Not Recommended\"\n",
    "\n",
    "# Order sentiment properly\n",
    "sentiment_order = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "keywords_df[\"sentiment\"] = pd.Categorical(\n",
    "    keywords_df[\"sentiment\"],\n",
    "    categories=sentiment_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Sort by sentiment, then count\n",
    "keywords_df = keywords_df.sort_values(\n",
    "    by=[\"sentiment\", \"count\"],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "\n",
    "# Export to CSV\n",
    "keywords_df.to_csv(\"non_recomm_keywords.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
